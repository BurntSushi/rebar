analysis = '''
These benchmarks test a few different variants of "overlapping words." That is,
we look for sequences of word characters of some length, and if that fails, we
fall back to a smaller sequence and so on. We in particular use this as a way
of contrasting how much Unicode hurts something like this. Namely the bounded
repeats greatly inflate the size of the regex and make matching quite a bit
harder, especially for automata oriented engines.

The difference between the `ascii` and Unicode aware benchmarks can be quite
brutal for automata engines. It can go from a bearable 50 MB/s for ASCII to
an eye watering 1 MB/s for Unicode. The main problem is that `\pL` is just
absolutely huge, and there is a lot of overhead associated with plowing through
the NFA states for it when resolving capture groups.
'''

[[bench]]
model = "grep-captures"
name = "ascii"
regex = '([A-Za-z]{14})|([A-Za-z]{13})|([A-Za-z]{12})|([A-Za-z]{11})|([A-Za-z]{10})|([A-Za-z]{9})|([A-Za-z]{8})|([A-Za-z]{7})|([A-Za-z]{6})|([A-Za-z]{5})'
haystack = { path = "opensubtitles/en-medium.txt" }
case-insensitive = false
count = 6_156
engines = [
  'go/regexp',
  'pcre2/jit',
  'python/regex',
  're2',
  'regress',
  'rust/regex',
  'rust/regexold',
]

[[bench]]
model = "grep-captures"
name = "english"
regex = '(\pL{14})|(\pL{13})|(\pL{12})|(\pL{11})|(\pL{10})|(\pL{9})|(\pL{8})|(\pL{7})|(\pL{6})|(\pL{5})'
haystack = { path = "opensubtitles/en-medium.txt" }
case-insensitive = false
unicode = true
count = 6_156
engines = [
  'go/regexp',
  'pcre2/jit',
  'python/regex',
  're2',
  'rust/regex',
  'rust/regexold',
]

[[bench]]
model = "grep-captures"
name = "russian"
regex = '(\pL{14})|(\pL{13})|(\pL{12})|(\pL{11})|(\pL{10})|(\pL{9})|(\pL{8})|(\pL{7})|(\pL{6})|(\pL{5})'
haystack = { path = "opensubtitles/ru-medium.txt" }
case-insensitive = false
unicode = true
count = 5_710
engines = [
  'go/regexp',
  'pcre2/jit',
  'python/regex',
  're2',
  'rust/regex',
  'rust/regexold',
]
