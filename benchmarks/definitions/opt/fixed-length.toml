analysis = '''
These benchmarks test "fixed length" optimizations. That is, for regexes with
no unbounded repetitions, one can compute the minimum and maximum lengths
that they can match. From those properties, one can sometimes reject a search
immediately based purely on the length of the haystack. The main complication
here is making sure things like a Unicode aware `.` contributes 4 to the
maximum since it could match up to 4 UTF-8 code units.

For minimums, things are relatively straight-forward. If your regex is
guaranteed to match at least 10 bytes and your haystack is less than that,
well, you can bail immediately.

Maximums are a little more tricky. Namely, if your regex is guaranteed to
match no more than 10 bytes and your haystack is longer than that, then you
can't necessarily bail because the regex could match anywhere. Thus, the
maximum optimization only kicks in when the regex is fully anchored at both
the start and end. In that case, the length of the haystack corresponds to
precisely how much the regex must match in order for a match to be reported
at all. And in that case, the maximum optimization kicks in.
'''

[[bench]]
model = "count"
name = "too-small-ascii"
regex = '\w{10,}'
haystack = 'abcdef'
count = 0
engines = [
  # Does it.
	'rust/regex',
  # Does not do it because it is a lower level regex engine. Included as a
  # point of comparison.
	'rust/regex/hybrid',
  # Does not do it.
  'rust/regexold',
  # Does not appear to do it.
  're2',
  # Does do it!
  'go/regexp',
]
analysis = '''
This benchmark tests that the regex engine fails very quickly when it knows
that a match is impossible because the haystack is too small. In this case,
the regex needs to match at least 10 word ASCII bytes, but the haystack
is shorter than that. You can see the difference between `rust/regex` and
`rust/regex/hybrid` for example.
'''

[[bench]]
model = "count"
name = "too-small-unicode"
regex = '[\p{math}&&\u{10000}-\u{10FFFF}]{10,}'
haystack = 'ğ›ƒğ›ƒğ›ƒğ›ƒğ›ƒğ›ƒğ›ƒğ›ƒğ›ƒ'
unicode = true
count = 0
engines = [
	'rust/regex',
  # Does not do it. Included as a point of comparison.
	'rust/regex/hybrid',
  # Does not do it.
  'rust/regexold',
]
analysis = '''
Same idea as `too-small-ascii`, but for Unicode.

We specifically use a codepoint that uses 4 bytes per encoding to ensure that
the maximum length computation for a Unicode-aware class is correct. And in
particular, we construct the class such that it only matches codepoints that
are encoded with 4 bytes. So the 9 instances of ğ›ƒ make up 36 bytes, which is 4
fewer than the minimum of 40 computed by the regex.

Sadly, the class intersection syntax isn't well supported, so we only measure
the regex crate. We could probably use a simpler regex with some effort, but
Â¯\\\_(ãƒ„)_/Â¯.
'''

[[bench]]
model = "count"
name = "too-big-ascii"
regex = '^\w{30}$'
haystack = 'abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz'
count = 0
engines = [
	'rust/regex',
  # Does not do it. Included as a point of comparison.
	'rust/regex/hybrid',
  # Does not do it.
  'rust/regexold',
  # Does not do it.
  're2',
  # Does not do it.
  # See: https://github.com/golang/go/issues/33484
  'go/regexp',
]
analysis = '''
This checks that we bail early when we know the haystack is too big to match.
'''

[[bench]]
model = "count"
name = "too-big-unicode"
regex = '^\w{10}$'
haystack = 'ğ›ƒğ›ƒğ›ƒğ›ƒğ›ƒğ›ƒğ›ƒğ›ƒğ›ƒğ›ƒğ›ƒ'
unicode = true
count = 0
engines = [
	'rust/regex',
  # Does not do it. Included as a point of comparison.
	'rust/regex/hybrid',
  # Does not do it.
  'rust/regexold',
]
analysis = '''
Same idea as `too-big-ascii`, but for Unicode.
'''

[[bench]]
model = "count"
name = "go33484-1"
regex = '^a{2,5}$'
haystack = { contents = 'a', repeat = 10_000 }
count = 0
engines = [
  'rust/regex',
  # Does not do it. Included as a point of comparison.
  'rust/regex/hybrid',
  # Does not do it.
  'rust/regexold',
  're2',
  'go/regexp',
]
analysis = '''
This comes from: https://github.com/golang/go/issues/33484
'''

[[bench]]
model = "count"
name = "go33484-2"
regex = '^((aaa)|(aa))$'
haystack = { contents = 'a', repeat = 10_000 }
count = 0
engines = [
  'rust/regex',
  # Does not do it. Included as a point of comparison.
  'rust/regex/hybrid',
  # Does not do it.
  'rust/regexold',
  're2',
  'go/regexp',
]
analysis = '''
This comes from: https://github.com/golang/go/issues/33484
'''

[[bench]]
model = "count"
name = "go33484-3"
regex = '^.{249}$'
unicode = true
haystack = { contents = 'a', repeat = 1_000 }
count = 0
engines = [
  'rust/regex',
  # Does not do it. Included as a point of comparison.
  'rust/regex/hybrid',
  # Does not do it.
  'rust/regexold',
  # Does not do it.
  're2',
  # Does not do it.
  'go/regexp',
]
analysis = '''
This comes from: https://github.com/golang/go/issues/33484

It was adapted slightly with a repetition to make the difference a bit more
noticeable.
'''
